{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "mLVXJRQ7tiBe",
    "Ao78SDEp1Xbf",
    "j0-Zs6KZ6Dgi",
    "L1nWOkGvCStj",
    "NySCEE0-tKw-",
    "7gGjGMljB24P",
    "dhZGQ72NODIZ",
    "CVApiSmm8ocW",
    "3bUGvgAqJfkt",
    "5QVu6_HVJTlW",
    "00kLaQZWS-Jq",
    "2dh9Zxt6NqAY",
    "dOIICEUZvjR0"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 此文档最后更新于2024年一月中旬\n",
    "author:aceliuchanghong@gmail.com"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 首先安装 anaconda 以及搭建环境(by the way:我是在google colab测试的)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 此处分开执行吧,中间很多需要自己点击enter的地方,最好后台跑\n",
    "! wget https: // repo.anaconda.com / archive / Anaconda3-2023.09-0-Linux-x86_64.sh\n",
    "! sh Anaconda3-2023.09-0-Linux-x86_64.sh\n",
    "! echo 'export PATH=/root/anaconda3/bin:$PATH' >> ~ /.bashrc\n",
    "! source ~ /.bashrc\n",
    "! conda env list\n",
    "! rm Anaconda3-2023.09-0-Linux-x86_64.sh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda create -n langchain_learn python=3.10\n",
    "!conda activate langchain_learn\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 概念\n",
    "```\n",
    "好了,第一个完成的朋友证明是想做的,那么让我们开始了解概念吧,或者说那些行话/术语\n",
    "```\n",
    "- 加载器\n",
    "-\n",
    "- Chain\n",
    "- Agent\n",
    "- Embedding\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 此文档教学目标==>通过使用langchain来达到学习目的\n",
    "```\n",
    "输入网页地址==>获得一个简明扼要的描述该地址网页内容的人声语音文件\n",
    "```\n",
    "* 爬虫获取网页内容==>输出该网页html主体文本(A.txt)\n",
    "* llm总结文本(A.txt)输出剧本(A.srt)\n",
    "* tts文字(A.srt)转语音输出音频文件(A.wav)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mError\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01muser_crawler\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore_crawler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Crawler\n\u001B[0;32m      4\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://www.sohu.com/a/744144846_121687421\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m file_txt, file_html \u001B[38;5;241m=\u001B[39m \u001B[43mCrawler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mliu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\aprojectPython\\pythonProject\\media_work_model\\user_crawler\\core_crawler.py:22\u001B[0m, in \u001B[0;36mCrawler.work\u001B[1;34m(self, url, user)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;124;03m爬取对于url,获取数据文件保存到{user}目录下存为{user}_output.txt\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 获取数据\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m content, response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to get data from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\aprojectPython\\pythonProject\\media_work_model\\core\\action\\base_crawler.py:215\u001B[0m, in \u001B[0;36mBaseCrawler._get\u001B[1;34m(self, url)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get\u001B[39m(\u001B[38;5;28mself\u001B[39m, url):\n\u001B[1;32m--> 215\u001B[0m     content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_html_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     ans \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_html_content(content)\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m content, ans\n",
      "File \u001B[1;32mD:\\aprojectPython\\pythonProject\\media_work_model\\core\\action\\base_crawler.py:96\u001B[0m, in \u001B[0;36mBaseCrawler.fetch_html_content\u001B[1;34m(self, url, content_selector)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;124;03mUse playwright to send GET requests and return the HTML content of the page.\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     94\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 96\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sync_playwright() \u001B[38;5;28;01mas\u001B[39;00m p:\n\u001B[0;32m     97\u001B[0m     browser \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mchromium\u001B[38;5;241m.\u001B[39mlaunch()\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;66;03m# Create a new browser context with the specified user agent\u001B[39;00m\n",
      "File \u001B[1;32mD:\\soft\\anaconda\\envs\\worker\\lib\\site-packages\\playwright\\sync_api\\_context_manager.py:47\u001B[0m, in \u001B[0;36mPlaywrightContextManager.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     45\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_own_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop\u001B[38;5;241m.\u001B[39mis_running():\n\u001B[1;32m---> 47\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Error(\n\u001B[0;32m     48\u001B[0m \u001B[38;5;250m                \u001B[39m\u001B[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03mPlease use the Async API instead.\"\"\"\u001B[39;00m\n\u001B[0;32m     50\u001B[0m             )\n\u001B[0;32m     52\u001B[0m         \u001B[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001B[39;00m\n\u001B[0;32m     53\u001B[0m         \u001B[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001B[39;00m\n\u001B[0;32m     54\u001B[0m         \u001B[38;5;66;03m# block while waiting for a response.\u001B[39;00m\n\u001B[0;32m     55\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgreenlet_main\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mError\u001B[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "import config\n",
    "from user_crawler.core_crawler import Crawler\n",
    "\n",
    "url = 'https://www.sohu.com/a/744144846_121687421'\n",
    "file_txt, file_html = Crawler(config).work(url, 'liu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
